{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer , make_blobs, load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../episcopeenvigado')\n",
    "\n",
    "import episcopeenvigado.dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae22e1",
   "metadata": {},
   "source": [
    "# Búsqueda en Rejilla y Validación Cruzada\n",
    "\n",
    "La validación cruzada es un método para evaluar el rendimiento.\n",
    "\n",
    "La búsqueda en rejilla, es un método para ajustar los parámetros en modelos supervisados ​​y mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95efcd5f",
   "metadata": {},
   "source": [
    "## Validación Cruzada \n",
    "\n",
    "Es un método estadístico para evaluar la capacidad de generalización: Los datos se dividen en pliegues (k-fold) y se entrenan múltiples modelos en cada pliegue. \n",
    "\n",
    "El primer modelo se entrena utilizando el pliegue 1 como conjunto de prueba, y los pliegues  2-5 como conjunto de entrenamiento. Posteriormente, se construye otro modelo con el pliegue 2 como conjunto de prueba y los datos de los pliegues 1, 3, 4 y 5 como conjunto de entrenamiento, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-05 00:45:57.415\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m179\u001b[0m - \u001b[32m\u001b[1m✅ Archivo 'analisis_coocurrencias_significativas' cargado con 2306 filas.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:45:58.322\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m179\u001b[0m - \u001b[32m\u001b[1m✅ Archivo 'consolidado_por_usuario_4dig' cargado con 35944 filas.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:45:58.511\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m179\u001b[0m - \u001b[32m\u001b[1m✅ Archivo 'frecuencia_diagnosticos_CIE4' cargado con 3985 filas.\u001b[0m\n",
      "dict_keys(['analisis_coocurrencias_significativas', 'consolidado_por_usuario_4dig', 'frecuencia_diagnosticos_CIE4'])\n",
      "Exactitud de la validación cruzada: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Eusse\\Documents\\ANALISIS DE DATOS\\Proyecto Final\\EpiScopeEnvigado\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from episcopeenvigado.config import PROCESSED_DATA_DIR\n",
    "\n",
    "# Cargar y guardar en sesión\n",
    "procesados_ds = ds.cargar_datasets_locales(PROCESSED_DATA_DIR)\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "#episcope_data = ds.obtener_dataset_completo()\n",
    "\n",
    "\n",
    "#dim_fact = episcope_data[\"fact_atenciones\"] \n",
    "print(procesados_ds.keys())\n",
    "#print(episcope_data.keys())\n",
    "#Por defecto, k=3\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5) \n",
    "print(\"Exactitud de la validación cruzada: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd6475",
   "metadata": {},
   "source": [
    "### Validación Cruzada estratificada\n",
    "\n",
    "Para modelos de clasificación, es recomendable utilizar la validación cruzada estratificada: dividimos los datos de manera que las proporciones entre las clases sean las mismas en cada partición que en el conjunto de datos completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0901019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_stratified_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iris labels:\\n{}\".format(iris.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kfold = KFold(n_splits=5)\n",
    "print(\"Cross-validation scores:\\n{}\".format( cross_val_score(logreg, iris.data, iris.target, cv=kfold)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa640ce",
   "metadata": {},
   "source": [
    "Otra opción es aleatorizar los datos en lugar de estratificar los pliegues, pero debemos fijar `random_state=0`. De lo contrario, cada ejecución de `cross_val_score` arrojaría un resultado diferente, ya que se usaría una división distinta en cada ocasión.\n",
    "\n",
    "`kfold = KFold(n_splits=3, shuffle=True, random_state=0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave-one-out: Cada fold representa una sola muestra \n",
    "# Para cada división, se selecciona un dato para el conjunto de prueba. (muy lento para grandes datos)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo) \n",
    "print(\"Número de iteraciones sobre cv: \", len(scores))\n",
    "print(\"Media del puntaje: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bcf8f3",
   "metadata": {},
   "source": [
    "### Validación cruzada con división aleatoria\n",
    "\n",
    "Cada división toma puntos para el conjunto de entrenamiento de `train_size` y para el conjunto de prueba de `test_size`. \n",
    "Esta división se repite `n_iter` veces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e688682",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_shuffle_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Divición del conjunto en 50% para entrenamiento y un 50% para prueba para 10 iteraciones\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10) \n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split) \n",
    "print(\"Extactidudes sobre la Validación cruzada:\\n{}\".format(scores))\n",
    "print('='*30)\n",
    "print('También se puede usar solo una parte de los datos en cada iteración\\nbasta con dar valores distintos en `train_size` y `test_size`\\nEste submuestreo puede ser útil con grandes conjuntos de datos.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b4a05",
   "metadata": {},
   "source": [
    "### Validación cruzada con grupos\n",
    "\n",
    "Cuando existen grupos de datos altamente relacionados, podemos usar `GroupKFold`, que toma como argumento un array que indica los grupos de datos que no deben dividirse al crear los conjuntos de entrenamiento y prueba, y no debe confundirse con la etiqueta de clase.\n",
    "\n",
    "Este caso es común en aplicaciones médicas, donde se pueden tener múltiples muestras del mismo paciente, pero se busca generalizar a nuevos pacientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X, y = make_blobs(n_samples=12, random_state=0)\n",
    "# las tres primeras muestras pertenecen al mismo grupo,\n",
    "# las cuatro siguientes pertenecen al mismo grupo, etc.\n",
    "groups=[0,0,0,1,1,1,1,2,2,3,3,3]\n",
    "scores = cross_val_score(estimator=logreg, X=X, y=y, groups=groups, cv=GroupKFold(n_splits=2)) \n",
    "print(\"Extactidudes sobre la Validación cruzada:\\n{}\".format(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1367788",
   "metadata": {},
   "source": [
    "## Búsqueda en Rejilla\n",
    "\n",
    "Es un método para encontrar los valores de los parámetros para un mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "            # Para cada combinación de parámetros, entrena SVC.\n",
    "            svm = SVC(gamma=gamma, C=C)\n",
    "            svm.fit(X_train, y_train)\n",
    "            # Evalúa SVC en el conjunto de prueba\n",
    "            score = svm.score(X_test, y_test)\n",
    "            # Almacena la puntuación y los parámetros para la mejor puntuación mejor \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Mejor exactitud: {:.2f}\".format(best_score)) \n",
    "print(\"Mejores parámetros: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c3760",
   "metadata": {},
   "source": [
    "### Overfiting\n",
    "\n",
    "Aunque la precisión sobre los datos de prueba es 97%, no necesariamente la precisión se mantendrá con nuevos datos. \n",
    "\n",
    "Dado que usamos los datos de prueba para ajustar los parámetros, ya no podemos usarlos para evaluar la calidad del modelo. Una forma de resolver este problema es dividir los datos nuevamente, de modo que tengamos tres conjuntos: \n",
    "1. datos de entrenamiento para construir el modelo\n",
    "2. datos de validación (o desarrollo) para seleccionar los parámetros del modelo\n",
    "3. datos de prueba para evaluar el rendimiento de los parámetros seleccionados. \n",
    "\n",
    "Seleccionamos los mejores parámetros usando el conjunto de validación y se entrena con los datos de entrenamiento y con los de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3802640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisióon train+validation dataset and test dataset\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# División train+validation dataset en training data y validation data  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "            # Para cada combinación de parámetros, entrena SVC.\n",
    "            svm = SVC(gamma=gamma, C=C)\n",
    "            svm.fit(X_train, y_train)\n",
    "            # Evalúa SVC en el conjunto de prueba \n",
    "            score = svm.score(X_valid, y_valid)\n",
    "            # Almacena la puntuación y los parámetros para la mejor puntuación mejor \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# Entreanmos el modelo con train+validation dataset y lo evaluamos con test dataset.\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Mejor puntaje sobre el conjunti de validación: {:.2f}\".format(best_score))\n",
    "print(\"Mejores parametros: \", best_parameters)\n",
    "print(\"Puntaje sobre datos de prueba con los mejores parametros: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280f81d",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba19f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=42)\n",
    "\n",
    "# Pipeline de dos pasos: \"scaler\" y \"svm\".\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC())])\n",
    "# .fit para usar el pipeline.\n",
    "pipe.fit(X_train, y_train)\n",
    "# .score para el puntaje del modelo\n",
    "print(\"Test score: {:.2f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3511c5d",
   "metadata": {},
   "source": [
    "## Pipelines para búsqueda en regillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La sintaxis para definir una grilla de parámetros para un Pipeline: \n",
    "# (Nombre del paso)__(nombre del parámetro). \n",
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5) \n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Mejor exactitud de validación cuzada: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"R^2 score: {:.2f}\".format(grid.score(X_test, y_test))) \n",
    "print(\"Mejores parámetros: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146b1c2",
   "metadata": {},
   "source": [
    "## Fuga de información en la validación cruzada\n",
    "\n",
    "Estimar la escala de los datos mediante el pliegue de prueba no suele tener un impacto significativo, mientras que su uso en la extracción y selección de características puede generar diferencias sustanciales en los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos, donde no existe relación entre variables\n",
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 10000))\n",
    "y = rnd.normal(size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f14b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "#SelectPercentile: seleccina la característica del percentil con R^2 más alto\n",
    "# y entrena el modelo mediante validación cruzada\n",
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y) \n",
    "X_selected = select.transform(X)\n",
    "print(\"X_selected.shape: {}\".format(X_selected.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a110348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Cross-validation accuracy (cv only on ridge): {:.2f}\".format(\n",
    "    np.mean(cross_val_score(Ridge(), X_selected, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03eaf5",
   "metadata": {},
   "source": [
    "El $R^2$ indica un modelo muy bueno. **Esto no puede ser correcto**, los datos son aleatorios.\n",
    "\n",
    "¿Qué sucedió? la selección de características eligió algunas (entre las 10 000 aleatorias), que (por azar) están bien correlacionadas. \n",
    "\n",
    "Dado que ajustamos la selección de características fuera de la validación cruzada, pudo encontrar características correlacionadas tanto en el conjunto de entrenamiento como en el de prueba. La información que se filtró del conjunto de prueba fue muy informativa, lo que condujo a resultados muy poco realistas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"select\", SelectPercentile(score_func=f_regression,\n",
    "                                                 percentile=5)),(\"ridge\", Ridge())]) \n",
    "\n",
    "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(\n",
    "    np.mean(cross_val_score(pipe, X, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c1369",
   "metadata": {},
   "source": [
    "$R^2$ cercano a cero, un modelo deficiente.\n",
    "\n",
    "Con el Pipeline la selección de características se encuentra ahora dentro del bucle de validación cruzada. Esto significa que las características solo se pueden seleccionar utilizando los pliegues de entrenamiento de los datos, no el pliegue de prueba. \n",
    "\n",
    "Se corrige el problema de fuga de datos en la selección de características y marca la diferencia entre concluir que un modelo funciona muy bien o concluir que no funciona en absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00474d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
