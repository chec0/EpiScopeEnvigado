{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e879db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-05 00:51:49.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mepiscopeenvigado.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Diego Eusse\\Documents\\ANALISIS DE DATOS\\Proyecto Final\\EpiScopeEnvigado\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer , make_blobs, load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../episcopeenvigado')\n",
    "\n",
    "import episcopeenvigado.dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae22e1",
   "metadata": {},
   "source": [
    "# B√∫squeda en Rejilla y Validaci√≥n Cruzada\n",
    "\n",
    "La validaci√≥n cruzada es un m√©todo para evaluar el rendimiento.\n",
    "\n",
    "La b√∫squeda en rejilla, es un m√©todo para ajustar los par√°metros en modelos supervisados ‚Äã‚Äãy mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95efcd5f",
   "metadata": {},
   "source": [
    "## Validaci√≥n Cruzada \n",
    "\n",
    "Es un m√©todo estad√≠stico para evaluar la capacidad de generalizaci√≥n: Los datos se dividen en pliegues (k-fold) y se entrenan m√∫ltiples modelos en cada pliegue. \n",
    "\n",
    "El primer modelo se entrena utilizando el pliegue 1 como conjunto de prueba, y los pliegues  2-5 como conjunto de entrenamiento. Posteriormente, se construye otro modelo con el pliegue 2 como conjunto de prueba y los datos de los pliegues 1, 3, 4 y 5 como conjunto de entrenamiento, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75057269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-05 00:56:07.768\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m184\u001b[0m - \u001b[32m\u001b[1m‚úÖ Archivo 'analisis_coocurrencias_significativas' cargado con 2306 filas.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:08.738\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m184\u001b[0m - \u001b[32m\u001b[1m‚úÖ Archivo 'consolidado_por_usuario_4dig' cargado con 35944 filas.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:08.919\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mcargar_datasets_locales\u001b[0m:\u001b[36m184\u001b[0m - \u001b[32m\u001b[1m‚úÖ Archivo 'frecuencia_diagnosticos_CIE4' cargado con 3985 filas.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1müìã Se encontraron 7 tablas en la base de datos.\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.266\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_causa_ext' cargada correctamente (14 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.400\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_cie10' cargada correctamente (12568 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.404\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_departamento' cargada correctamente (34 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.406\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_estado_salida' cargada correctamente (2 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.415\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_municipio' cargada correctamente (1124 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:09.417\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'dim_via_ingreso' cargada correctamente (9 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:10.501\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m118\u001b[0m - \u001b[32m\u001b[1m‚úÖ Tabla 'fact_atenciones' cargada correctamente (45303 filas).\u001b[0m\n",
      "\u001b[32m2025-11-05 00:56:10.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mepiscopeenvigado.dataset\u001b[0m:\u001b[36mobtener_dataset_completo\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m‚úÖ Dataset completo cargado (7 tablas exitosas).\u001b[0m\n",
      "dict_keys(['analisis_coocurrencias_significativas', 'consolidado_por_usuario_4dig', 'frecuencia_diagnosticos_CIE4'])\n",
      "dict_keys(['dim_causa_ext', 'dim_cie10', 'dim_departamento', 'dim_estado_salida', 'dim_municipio', 'dim_via_ingreso', 'fact_atenciones'])\n"
     ]
    }
   ],
   "source": [
    "from episcopeenvigado.config import PROCESSED_DATA_DIR\n",
    "# Cargar y guardar en sesi√≥n\n",
    "procesados_ds = ds.cargar_datasets_locales(PROCESSED_DATA_DIR)\n",
    "\n",
    "episcope_data = ds.obtener_dataset_completo()\n",
    "\n",
    "\n",
    "dim_fact = episcope_data[\"fact_atenciones\"] \n",
    "print(procesados_ds.keys())\n",
    "print(episcope_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#Por defecto, k=3\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5) \n",
    "print(\"Exactitud de la validaci√≥n cruzada: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd6475",
   "metadata": {},
   "source": [
    "### Validaci√≥n Cruzada estratificada\n",
    "\n",
    "Para modelos de clasificaci√≥n, es recomendable utilizar la validaci√≥n cruzada estratificada: dividimos los datos de manera que las proporciones entre las clases sean las mismas en cada partici√≥n que en el conjunto de datos completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0901019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_stratified_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iris labels:\\n{}\".format(iris.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kfold = KFold(n_splits=5)\n",
    "print(\"Cross-validation scores:\\n{}\".format( cross_val_score(logreg, iris.data, iris.target, cv=kfold)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa640ce",
   "metadata": {},
   "source": [
    "Otra opci√≥n es aleatorizar los datos en lugar de estratificar los pliegues, pero debemos fijar `random_state=0`. De lo contrario, cada ejecuci√≥n de `cross_val_score` arrojar√≠a un resultado diferente, ya que se usar√≠a una divisi√≥n distinta en cada ocasi√≥n.\n",
    "\n",
    "`kfold = KFold(n_splits=3, shuffle=True, random_state=0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave-one-out: Cada fold representa una sola muestra \n",
    "# Para cada divisi√≥n, se selecciona un dato para el conjunto de prueba. (muy lento para grandes datos)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo) \n",
    "print(\"N√∫mero de iteraciones sobre cv: \", len(scores))\n",
    "print(\"Media del puntaje: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bcf8f3",
   "metadata": {},
   "source": [
    "### Validaci√≥n cruzada con divisi√≥n aleatoria\n",
    "\n",
    "Cada divisi√≥n toma puntos para el conjunto de entrenamiento de `train_size` y para el conjunto de prueba de `test_size`. \n",
    "Esta divisi√≥n se repite `n_iter` veces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e688682",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_shuffle_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Divici√≥n del conjunto en 50% para entrenamiento y un 50% para prueba para 10 iteraciones\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10) \n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split) \n",
    "print(\"Extactidudes sobre la Validaci√≥n cruzada:\\n{}\".format(scores))\n",
    "print('='*30)\n",
    "print('Tambi√©n se puede usar solo una parte de los datos en cada iteraci√≥n\\nbasta con dar valores distintos en `train_size` y `test_size`\\nEste submuestreo puede ser √∫til con grandes conjuntos de datos.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b4a05",
   "metadata": {},
   "source": [
    "### Validaci√≥n cruzada con grupos\n",
    "\n",
    "Cuando existen grupos de datos altamente relacionados, podemos usar `GroupKFold`, que toma como argumento un array que indica los grupos de datos que no deben dividirse al crear los conjuntos de entrenamiento y prueba, y no debe confundirse con la etiqueta de clase.\n",
    "\n",
    "Este caso es com√∫n en aplicaciones m√©dicas, donde se pueden tener m√∫ltiples muestras del mismo paciente, pero se busca generalizar a nuevos pacientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X, y = make_blobs(n_samples=12, random_state=0)\n",
    "# las tres primeras muestras pertenecen al mismo grupo,\n",
    "# las cuatro siguientes pertenecen al mismo grupo, etc.\n",
    "groups=[0,0,0,1,1,1,1,2,2,3,3,3]\n",
    "scores = cross_val_score(estimator=logreg, X=X, y=y, groups=groups, cv=GroupKFold(n_splits=2)) \n",
    "print(\"Extactidudes sobre la Validaci√≥n cruzada:\\n{}\".format(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1367788",
   "metadata": {},
   "source": [
    "## B√∫squeda en Rejilla\n",
    "\n",
    "Es un m√©todo para encontrar los valores de los par√°metros para un mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "            # Para cada combinaci√≥n de par√°metros, entrena SVC.\n",
    "            svm = SVC(gamma=gamma, C=C)\n",
    "            svm.fit(X_train, y_train)\n",
    "            # Eval√∫a SVC en el conjunto de prueba\n",
    "            score = svm.score(X_test, y_test)\n",
    "            # Almacena la puntuaci√≥n y los par√°metros para la mejor puntuaci√≥n mejor \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Mejor exactitud: {:.2f}\".format(best_score)) \n",
    "print(\"Mejores par√°metros: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c3760",
   "metadata": {},
   "source": [
    "### Overfiting\n",
    "\n",
    "Aunque la precisi√≥n sobre los datos de prueba es 97%, no necesariamente la precisi√≥n se mantendr√° con nuevos datos. \n",
    "\n",
    "Dado que usamos los datos de prueba para ajustar los par√°metros, ya no podemos usarlos para evaluar la calidad del modelo. Una forma de resolver este problema es dividir los datos nuevamente, de modo que tengamos tres conjuntos: \n",
    "1. datos de entrenamiento para construir el modelo\n",
    "2. datos de validaci√≥n (o desarrollo) para seleccionar los par√°metros del modelo\n",
    "3. datos de prueba para evaluar el rendimiento de los par√°metros seleccionados. \n",
    "\n",
    "Seleccionamos los mejores par√°metros usando el conjunto de validaci√≥n y se entrena con los datos de entrenamiento y con los de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3802640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥on train+validation dataset and test dataset\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# Divisi√≥n train+validation dataset en training data y validation data  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "            # Para cada combinaci√≥n de par√°metros, entrena SVC.\n",
    "            svm = SVC(gamma=gamma, C=C)\n",
    "            svm.fit(X_train, y_train)\n",
    "            # Eval√∫a SVC en el conjunto de prueba \n",
    "            score = svm.score(X_valid, y_valid)\n",
    "            # Almacena la puntuaci√≥n y los par√°metros para la mejor puntuaci√≥n mejor \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# Entreanmos el modelo con train+validation dataset y lo evaluamos con test dataset.\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Mejor puntaje sobre el conjunti de validaci√≥n: {:.2f}\".format(best_score))\n",
    "print(\"Mejores parametros: \", best_parameters)\n",
    "print(\"Puntaje sobre datos de prueba con los mejores parametros: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280f81d",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba19f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=42)\n",
    "\n",
    "# Pipeline de dos pasos: \"scaler\" y \"svm\".\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC())])\n",
    "# .fit para usar el pipeline.\n",
    "pipe.fit(X_train, y_train)\n",
    "# .score para el puntaje del modelo\n",
    "print(\"Test score: {:.2f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3511c5d",
   "metadata": {},
   "source": [
    "## Pipelines para b√∫squeda en regillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La sintaxis para definir una grilla de par√°metros para un Pipeline: \n",
    "# (Nombre del paso)__(nombre del par√°metro). \n",
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5) \n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Mejor exactitud de validaci√≥n cuzada: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"R^2 score: {:.2f}\".format(grid.score(X_test, y_test))) \n",
    "print(\"Mejores par√°metros: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146b1c2",
   "metadata": {},
   "source": [
    "## Fuga de informaci√≥n en la validaci√≥n cruzada\n",
    "\n",
    "Estimar la escala de los datos mediante el pliegue de prueba no suele tener un impacto significativo, mientras que su uso en la extracci√≥n y selecci√≥n de caracter√≠sticas puede generar diferencias sustanciales en los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos, donde no existe relaci√≥n entre variables\n",
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 10000))\n",
    "y = rnd.normal(size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f14b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "#SelectPercentile: seleccina la caracter√≠stica del percentil con R^2 m√°s alto\n",
    "# y entrena el modelo mediante validaci√≥n cruzada\n",
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y) \n",
    "X_selected = select.transform(X)\n",
    "print(\"X_selected.shape: {}\".format(X_selected.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a110348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Cross-validation accuracy (cv only on ridge): {:.2f}\".format(\n",
    "    np.mean(cross_val_score(Ridge(), X_selected, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03eaf5",
   "metadata": {},
   "source": [
    "El $R^2$ indica un modelo muy bueno. **Esto no puede ser correcto**, los datos son aleatorios.\n",
    "\n",
    "¬øQu√© sucedi√≥? la selecci√≥n de caracter√≠sticas eligi√≥ algunas (entre las 10 000 aleatorias), que (por azar) est√°n bien correlacionadas. \n",
    "\n",
    "Dado que ajustamos la selecci√≥n de caracter√≠sticas fuera de la validaci√≥n cruzada, pudo encontrar caracter√≠sticas correlacionadas tanto en el conjunto de entrenamiento como en el de prueba. La informaci√≥n que se filtr√≥ del conjunto de prueba fue muy informativa, lo que condujo a resultados muy poco realistas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"select\", SelectPercentile(score_func=f_regression,\n",
    "                                                 percentile=5)),(\"ridge\", Ridge())]) \n",
    "\n",
    "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(\n",
    "    np.mean(cross_val_score(pipe, X, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c1369",
   "metadata": {},
   "source": [
    "$R^2$ cercano a cero, un modelo deficiente.\n",
    "\n",
    "Con el Pipeline la selecci√≥n de caracter√≠sticas se encuentra ahora dentro del bucle de validaci√≥n cruzada. Esto significa que las caracter√≠sticas solo se pueden seleccionar utilizando los pliegues de entrenamiento de los datos, no el pliegue de prueba. \n",
    "\n",
    "Se corrige el problema de fuga de datos en la selecci√≥n de caracter√≠sticas y marca la diferencia entre concluir que un modelo funciona muy bien o concluir que no funciona en absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00474d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
